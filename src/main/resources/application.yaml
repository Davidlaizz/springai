spring:
  application:
    name: spring-ai
  ai:
#    ollama:
#      base-url: http://localhost:11434
#      chat:
#        model: deepseek-r1:7b
    openai:
      base-url: https://dashscope.aliyuncs.com/compatible-mode
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: qwen-max-latest
          temperature: 0.8 # 模型温度，值越大模型越随机
logging:
  level:
      org.springframework.ai.chat.client.advisor: debug
      com.heima.ai: debug
